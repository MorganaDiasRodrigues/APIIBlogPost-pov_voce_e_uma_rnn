{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Camada RNN do torch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saída: 0.788179874420166\n",
      "Hidden state: 0.788179874420166\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# Seed para reprodução de resultados\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Instanciando a rede\n",
    "rnn = nn.RNN(1, 1, 1)\n",
    "# tamanho_da_sequência = 1, batch_size = 1, input_size = 1\n",
    "input = torch.tensor([[[0.5]]])\n",
    "\n",
    "# número_de_camadas * 1, batch_size, hidden_size\n",
    "hidden = torch.zeros(1, 1, 1)\n",
    "\n",
    "# Passando a entrada e o estado oculto pela RNN\n",
    "output, new_hidden = rnn(input, hidden)\n",
    "# Resultado\n",
    "print(f'Saída: {output[0][0][0]}')\n",
    "print(f'Hidden state: {new_hidden[0][0][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acessando os pesos e bias da rede para computar a função Tahn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como explicamos no blog, o que a camada realiza é a computação da seguinte fórmula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "h_t = \\tanh(x_t W_{ih}^T + b_{ih} + h_{t-1} W_{hh}^T + b_{hh})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onde os elementos de pesos e bias, representados por $W$ e $b$, colocados abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessando os pesos e bias da RNN\n",
    "w_ih = rnn.weight_ih_l0  # Peso para a entrada para a camada oculta\n",
    "w_hh = rnn.weight_hh_l0  # Peso para a camada oculta para a camada oculta\n",
    "b_ih = rnn.bias_ih_l0    # Bias para a entrada para a camada oculta\n",
    "b_hh = rnn.bias_hh_l0    # Bias para a camada oculta para a camada oculta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E o elemento $x_t$ da fórmula se refere à nossa entrada e o elemento $h_t$ se refere ao hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como temos todos estes elementos, podemos calcular 'manualmente' a mesma função com eles e observar o mesmo resultado de saída que a cadama RNN nos retornou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado da fórmula: 0.788179874420166\n"
     ]
    }
   ],
   "source": [
    "hidden_manual = torch.tanh(w_ih @ input[0] + b_ih + w_hh @ hidden + b_hh)\n",
    "print(f'Resultado da fórmula: {hidden_manual[0][0][0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
