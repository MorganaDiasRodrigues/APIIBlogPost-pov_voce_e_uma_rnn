{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerando nomes brasileiros com RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos fazer a previsão do próximo caractere baseado em uma lista de nomes brasileiros! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x18d425e53d0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# seed, para reproducibilidade\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carrega_dados(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        nomes = file.read().strip().split('\\n')\n",
    "    return nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 primeiros nomes: ['Ana', 'Lucas', 'Maria', 'João', 'Sofia']\n"
     ]
    }
   ],
   "source": [
    "nomes = carrega_dados('nomes_pt.txt')\n",
    "print(f'5 primeiros nomes: {nomes[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adicionando os tokens de Início e Fim dos nomes\n",
    "\n",
    "Para ajudar o modelo a entender onde começou e onde terminou o nome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b/Ana/e', 'b/Lucas/e', 'b/Maria/e', 'b/João/e', 'b/Sofia/e']\n"
     ]
    }
   ],
   "source": [
    "nomes = ['b/' + nome + '/e' for nome in nomes]\n",
    "print(nomes[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando o vocabulário, o encoder e o decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocabulário: 47 caracteres únicos\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(''.join(nomes))) # Aqui, o vocabulário é o conjunto de todos os caracteres únicos presentes nos nomes\n",
    "print(f'Tamanho do vocabulário: {len(vocab)} caracteres únicos')\n",
    "encoder = {ch: i for i, ch in enumerate(vocab)} # Aqui, criamos um dicionário que mapeia cada caractere para um índice\n",
    "decoder = {i: ch for i, ch in enumerate(vocab)} # Aqui, criamos um dicionário que mapeia cada índice para um caractere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A letra L está codificada como o número 11\n"
     ]
    }
   ],
   "source": [
    "print(f'A letra L está codificada como o número {encoder[\"L\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções auxiliares para o pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para mapear cada caractere codificado para um tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = encoder[string[c]]\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome Lucas codificado e em tensor: tensor([11, 37, 21, 19, 35])\n"
     ]
    }
   ],
   "source": [
    "print(f'Nome Lucas codificado e em tensor: {char_tensor(\"Lucas\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(tensor):\n",
    "    return torch.nn.functional.one_hot(tensor, num_classes=len(vocab)).type(torch.float32) # Vai retornar um tensor com o tamanho do vocabulário, com 1s nas posições correspondentes aos caracteres presentes no tensor de entrada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoding do nome Lucas: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) \n",
      "\n",
      "Tamanho do one-hot encoding: torch.Size([5, 47])\n"
     ]
    }
   ],
   "source": [
    "ohe_exemplo = one_hot_encoding(char_tensor('Lucas'))\n",
    "print(f'One-hot encoding do nome Lucas: {ohe_exemplo} \\n')\n",
    "# Veja que em algumas posições, há o número 1. Signifa que ali havia alguma letra correspondente ao nome 'Lucas'\n",
    "print(f'Tamanho do one-hot encoding: {ohe_exemplo.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo RNN para previsão do próximo caractere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True) # Olha aqui nossa diva! O shape dela será (tamanho_do_vocab, 100, tamanho_do_vocab)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        out, hidden = self.rnn(input, hidden)\n",
    "        out = self.fc(out[:, -1, :]) # Pega o último output da sequência\n",
    "        return out, hidden # Sempre retornar hidden para a próxima iteração\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, hidden_size) # Vamos inicializar o hidden com zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instanciando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 100\n",
    "model = CharRNN(len(vocab), hidden_size, len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definindo nossa função de perda e nosso otimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_line_tensor, target_char_tensor, device):\n",
    "    if device == 'cuda':\n",
    "        input_line_tensor = input_line_tensor.cuda()\n",
    "        target_char_tensor = target_char_tensor.cuda()\n",
    "        model.to(device)\n",
    "    hidden = model.init_hidden(1)\n",
    "    hidden = hidden.to(device)\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(input_line_tensor.size(0) - 1):\n",
    "        input = input_line_tensor[i:i+1].unsqueeze(0)\n",
    "        target = target_char_tensor[i+1]\n",
    "        output, hidden = model(input, hidden)\n",
    "        loss += loss_fn(output, target.view(1))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item() / (input_line_tensor.size(0) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.2929\n",
      "Epoch: 50, Loss: 0.6604\n",
      "Epoch: 100, Loss: 0.6915\n",
      "Epoch: 150, Loss: 1.0655\n",
      "Epoch: 200, Loss: 0.6139\n",
      "Epoch: 250, Loss: 0.6143\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 300 # Número de épocas que vamos treinar\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda' # Usaremos a GPU se disponível\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for name in nomes:\n",
    "        name_tensor = one_hot_encoding(char_tensor(name))\n",
    "        name_tensor.to(device)\n",
    "        loss = train(name_tensor, char_tensor(name), device=device)\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A melhor hora: Vamos fazer inferências com nosso modelo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para geração de nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(initial_char, max_length=12): # Initial_char é a letra que a rede vai usar para começar a gerar nomes e o max_length é o tamanho máximo do nome gerado. Eu definir 12, mas você pode mudar.\n",
    "    with torch.no_grad(): \n",
    "        hidden = model.init_hidden(1).to(device)\n",
    "        input_char_tensor = one_hot_encoding(char_tensor(initial_char)).to(device)\n",
    "        predicted_name = initial_char\n",
    "\n",
    "        for _ in range(max_length - 1):\n",
    "            input = input_char_tensor.unsqueeze(0)\n",
    "            output, hidden = model(input, hidden)\n",
    "\n",
    "            _ , topi = output.topk(1) # Vamos pegar o índice do maior valor, que é a previsão da rede para o próximo caractere\n",
    "            char_index = topi[0][0].item()\n",
    "            if char_index == encoder[initial_char]:\n",
    "                break\n",
    "            else:\n",
    "                char = decoder[char_index]\n",
    "                predicted_name += char\n",
    "                input_char_tensor = one_hot_encoding(char_tensor(char)).to(device)\n",
    "\n",
    "        return predicted_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando nomes 😁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharRNN(\n",
       "  (rnn): RNN(47, 100, batch_first=True)\n",
       "  (fc): Linear(in_features=100, out_features=47, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device) # Colocando o modelo na GPU\n",
    "model.eval()  # E colocando ele em modo de avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome gerado com o caractere 'L': Lívia\n"
     ]
    }
   ],
   "source": [
    "start_char = 'L'\n",
    "predicted_name = generate(start_char)\n",
    "# Pegar os caractres até o /\n",
    "print(f\"Nome gerado com o caractere '{start_char}': {predicted_name.split('/')[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome gerado com o caractere 'M': Mardo\n"
     ]
    }
   ],
   "source": [
    "start_char = 'M'\n",
    "predicted_name = generate(start_char)\n",
    "print(f\"Nome gerado com o caractere '{start_char}': {predicted_name.split('/')[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome gerado com o caractere 'D': Danciss\n"
     ]
    }
   ],
   "source": [
    "start_char = 'D'\n",
    "predicted_name = generate(start_char)\n",
    "print(f\"Nome gerado com o caractere '{start_char}': {predicted_name.split('/')[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome gerado com o caractere 'P': Pedoísna\n"
     ]
    }
   ],
   "source": [
    "start_char = 'P'\n",
    "predicted_name = generate(start_char)\n",
    "print(f\"Nome gerado com o caractere '{start_char}': {predicted_name.split('/')[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome gerado com o caractere 'Y': Yasmindo\n"
     ]
    }
   ],
   "source": [
    "start_char = 'Y'\n",
    "predicted_name = generate(start_char)\n",
    "print(f\"Nome gerado com o caractere '{start_char}': {predicted_name.split('/')[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão:\n",
    "\n",
    "Por esta lista ser super curta, somente com 70 nomes, o modelo tem algumas limitações como não conseguir gerar nomes que começam com O (porque não tem nomes com essa letra na lista) além de ter pocuso exemplares de nomes diversos.\n",
    "\n",
    "Porém o intuito aqui era apenas exemplificar o uso da RNN :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
