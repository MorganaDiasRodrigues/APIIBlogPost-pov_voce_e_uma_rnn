{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerando nomes brasileiros com RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos fazer a previs√£o do pr√≥ximo caractere baseado em uma lista de nomes brasileiros! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x18d425e53d0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# seed, para reproducibilidade\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carrega_dados(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        nomes = file.read().strip().split('\\n')\n",
    "    return nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 primeiros nomes: ['Ana', 'Lucas', 'Maria', 'Jo√£o', 'Sofia']\n"
     ]
    }
   ],
   "source": [
    "nomes = carrega_dados('nomes_pt.txt')\n",
    "print(f'5 primeiros nomes: {nomes[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adicionando os tokens de In√≠cio e Fim dos nomes\n",
    "\n",
    "Para ajudar o modelo a entender onde come√ßou e onde terminou o nome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b/Ana/e', 'b/Lucas/e', 'b/Maria/e', 'b/Jo√£o/e', 'b/Sofia/e']\n"
     ]
    }
   ],
   "source": [
    "nomes = ['b/' + nome + '/e' for nome in nomes]\n",
    "print(nomes[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando o vocabul√°rio, o encoder e o decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocabul√°rio: 47 caracteres √∫nicos\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(''.join(nomes))) # Aqui, o vocabul√°rio √© o conjunto de todos os caracteres √∫nicos presentes nos nomes\n",
    "print(f'Tamanho do vocabul√°rio: {len(vocab)} caracteres √∫nicos')\n",
    "encoder = {ch: i for i, ch in enumerate(vocab)} # Aqui, criamos um dicion√°rio que mapeia cada caractere para um √≠ndice\n",
    "decoder = {i: ch for i, ch in enumerate(vocab)} # Aqui, criamos um dicion√°rio que mapeia cada √≠ndice para um caractere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A letra L est√° codificada como o n√∫mero 11\n"
     ]
    }
   ],
   "source": [
    "print(f'A letra L est√° codificada como o n√∫mero {encoder[\"L\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√µes auxiliares para o pr√©-processamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fun√ß√£o para mapear cada caractere codificado para um tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = encoder[string[c]]\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome Lucas codificado e em tensor: tensor([11, 37, 21, 19, 35])\n"
     ]
    }
   ],
   "source": [
    "print(f'Nome Lucas codificado e em tensor: {char_tensor(\"Lucas\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(tensor):\n",
    "    return torch.nn.functional.one_hot(tensor, num_classes=len(vocab)).type(torch.float32) # Vai retornar um tensor com o tamanho do vocabul√°rio, com 1s nas posi√ß√µes correspondentes aos caracteres presentes no tensor de entrada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoding do nome Lucas: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) \n",
      "\n",
      "Tamanho do one-hot encoding: torch.Size([5, 47])\n"
     ]
    }
   ],
   "source": [
    "ohe_exemplo = one_hot_encoding(char_tensor('Lucas'))\n",
    "print(f'One-hot encoding do nome Lucas: {ohe_exemplo} \\n')\n",
    "# Veja que em algumas posi√ß√µes, h√° o n√∫mero 1. Signifa que ali havia alguma letra correspondente ao nome 'Lucas'\n",
    "print(f'Tamanho do one-hot encoding: {ohe_exemplo.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo RNN para previs√£o do pr√≥ximo caractere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True) # Olha aqui nossa diva! O shape dela ser√° (tamanho_do_vocab, 100, tamanho_do_vocab)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        out, hidden = self.rnn(input, hidden)\n",
    "        out = self.fc(out[:, -1, :]) # Pega o √∫ltimo output da sequ√™ncia\n",
    "        return out, hidden # Sempre retornar hidden para a pr√≥xima itera√ß√£o\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, hidden_size) # Vamos inicializar o hidden com zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instanciando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 100\n",
    "model = CharRNN(len(vocab), hidden_size, len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definindo nossa fun√ß√£o de perda e nosso otimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fun√ß√£o de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_line_tensor, target_char_tensor, device):\n",
    "    if device == 'cuda':\n",
    "        input_line_tensor = input_line_tensor.cuda()\n",
    "        target_char_tensor = target_char_tensor.cuda()\n",
    "        model.to(device)\n",
    "    hidden = model.init_hidden(1)\n",
    "    hidden = hidden.to(device)\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(input_line_tensor.size(0) - 1):\n",
    "        input = input_line_tensor[i:i+1].unsqueeze(0)\n",
    "        target = target_char_tensor[i+1]\n",
    "        output, hidden = model(input, hidden)\n",
    "        loss += loss_fn(output, target.view(1))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item() / (input_line_tensor.size(0) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.2929\n",
      "Epoch: 50, Loss: 0.6604\n",
      "Epoch: 100, Loss: 0.6915\n",
      "Epoch: 150, Loss: 1.0655\n",
      "Epoch: 200, Loss: 0.6139\n",
      "Epoch: 250, Loss: 0.6143\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 300 # N√∫mero de √©pocas que vamos treinar\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda' # Usaremos a GPU se dispon√≠vel\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for name in nomes:\n",
    "        name_tensor = one_hot_encoding(char_tensor(name))\n",
    "        name_tensor.to(device)\n",
    "        loss = train(name_tensor, char_tensor(name), device=device)\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A melhor hora: Vamos fazer infer√™ncias com nosso modelo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fun√ß√£o para gera√ß√£o de nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(initial_char, max_length=12): # Initial_char √© a letra que a rede vai usar para come√ßar a gerar nomes e o max_length √© o tamanho m√°ximo do nome gerado. Eu definir 12, mas voc√™ pode mudar.\n",
    "    with torch.no_grad(): \n",
    "        hidden = model.init_hidden(1).to(device)\n",
    "        input_char_tensor = one_hot_encoding(char_tensor(initial_char)).to(device)\n",
    "        predicted_name = initial_char\n",
    "\n",
    "        for _ in range(max_length - 1):\n",
    "            input = input_char_tensor.unsqueeze(0)\n",
    "            output, hidden = model(input, hidden)\n",
    "\n",
    "            _ , topi = output.topk(1) # Vamos pegar o √≠ndice do maior valor, que √© a previs√£o da rede para o pr√≥ximo caractere\n",
    "            char_index = topi[0][0].item()\n",
    "            if char_index == encoder[initial_char]:\n",
    "                break\n",
    "            else:\n",
    "                char = decoder[char_index]\n",
    "                predicted_name += char\n",
    "                input_char_tensor = one_hot_encoding(char_tensor(char)).to(device)\n",
    "\n",
    "        return predicted_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando nomes üòÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharRNN(\n",
       "  (rnn): RNN(47, 100, batch_first=True)\n",
       "  (fc): Linear(in_features=100, out_features=47, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device) # Colocando o modelo na GPU\n",
    "model.eval()  # E colocando ele em modo de avalia√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome gerado com o caractere 'L': L√≠via\n"
     ]
    }
   ],
   "source": [
    "start_char = 'L'\n",
    "predicted_name = generate(start_char)\n",
    "# Pegar os caractres at√© o /\n",
    "print(f\"Nome gerado com o caractere '{start_char}': {predicted_name.split('/')[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome gerado com o caractere 'M': Mardo\n"
     ]
    }
   ],
   "source": [
    "start_char = 'M'\n",
    "predicted_name = generate(start_char)\n",
    "print(f\"Nome gerado com o caractere '{start_char}': {predicted_name.split('/')[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome gerado com o caractere 'D': Danciss\n"
     ]
    }
   ],
   "source": [
    "start_char = 'D'\n",
    "predicted_name = generate(start_char)\n",
    "print(f\"Nome gerado com o caractere '{start_char}': {predicted_name.split('/')[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome gerado com o caractere 'P': Pedo√≠sna\n"
     ]
    }
   ],
   "source": [
    "start_char = 'P'\n",
    "predicted_name = generate(start_char)\n",
    "print(f\"Nome gerado com o caractere '{start_char}': {predicted_name.split('/')[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome gerado com o caractere 'Y': Yasmindo\n"
     ]
    }
   ],
   "source": [
    "start_char = 'Y'\n",
    "predicted_name = generate(start_char)\n",
    "print(f\"Nome gerado com o caractere '{start_char}': {predicted_name.split('/')[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclus√£o:\n",
    "\n",
    "Por esta lista ser super curta, somente com 70 nomes, o modelo tem algumas limita√ß√µes como n√£o conseguir gerar nomes que come√ßam com O (porque n√£o tem nomes com essa letra na lista) al√©m de ter pocuso exemplares de nomes diversos.\n",
    "\n",
    "Por√©m o intuito aqui era apenas exemplificar o uso da RNN :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
